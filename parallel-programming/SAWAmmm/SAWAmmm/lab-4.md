## Лабораторная работа №4
### Параллельное сложение матриц с горизонтальным распределением

**Дисциплина:** Теория параллельного программирования

**Выполнил(и):**
- Алешин Иван Кириллович

**Группа:** ПИН-31

**Дата:** 26.01.2026

**Подпись**:

---

## Аннотация

В данной лабораторной работе реализуется и сравнивается несколько методов параллельного сложения двух матриц размера N×N: последовательный, с использованием Task, Parallel.For и SIMD (AVX). Вводятся параметры N (размер матрицы), B (размер блока), P (число потоков). Особое внимание уделяется горизонтальному распределению работы между потоками. Программа позволяет оценить производительность различных подходов к параллельной обработке данных.

---

## Содержание

1. [[#1. Назначение и условия применения|Назначение и условия применения]]
2. [[#2. Характеристика программы|Характеристика программы]]
3. [[#3. Описание алгоритма|Описание алгоритма]]
4. [[#4. Используемые технологии программирования|Используемые технологии программирования]]
5. [[#5. Входные и выходные данные|Входные и выходные данные]]
6. [[#6. Результаты тестирования|Результаты тестирования]]

---

## 1. Назначение и условия применения

### 1.1 Назначение программы

Программа предназначена для сравнения производительности различных методов параллельного сложения двух матриц размера N×N с горизонтальным распределением работы между потоками.

### 1.2 Функции, выполняемые программой

- Генерация случайных матриц A и B размера N×N
- Сложение матриц A и B с получением матрицы C
- Реализация последовательного и параллельных методов (Task, Parallel.For, AVX)
- Измерение времени выполнения каждого метода
- Сравнение результатов и производительности

### 1.3 Условия, необходимые для выполнения программы

**Требования к аппаратному обеспечению:**
- Процессор: Ryzen 4500U (желательно поддержка AVX2 для SIMD)
- Оперативная память: DDR4 16 Gb 2666MHZ

**Требования к программному обеспечению:**
- Операционная система: Windows 11
- Компилятор: dotnet 9.0
- Библиотеки: System.Threading.Tasks, System.Numerics (для SIMD)
- Дополнительное ПО: Не требуется

**Требования к персоналу:**
- Базовые знания C#
- Понимание основ параллельного программирования

---

## 2. Характеристика программы

### 2.1 Режим работы

Программа работает в интерактивном режиме, поддерживает однопоточное и многопоточное выполнение задач, а также SIMD-ускорение.

### 2.2 Средства контроля правильности

Корректность работы программы проверяется сравнением результатов всех методов между собой (матрицы должны совпадать).

---

## 3. Описание алгоритма

### 3.1 Общая схема алгоритма

Вводятся параметры N (размер матрицы), B (размер блока), P (число потоков). Генерируются две матрицы A и B. Для каждого метода (последовательный, Task, Parallel.For, AVX) выполняется сложение матриц с горизонтальным распределением строк между потоками. Измеряется время выполнения, результаты сравниваются между собой.

### 3.2 Последовательная реализация

Двойной цикл по всем элементам матрицы:
```csharp
for (int i = 0; i < N; i++)
    for (int j = 0; j < N; j++)
        C[i, j] = A[i, j] + B[i, j];
```

### 3.3 Параллельная реализация

- **Task:** Матрица разбивается на P горизонтальных полос, каждая Task обрабатывает свою полосу.
- **Parallel.For:** Внешний цикл по строкам распараллеливается автоматически.
- **AVX:** Каждая полоса обрабатывается с помощью SIMD-инструкций (по 8 элементов за раз).

Во всех параллельных методах строки матрицы делятся между потоками горизонтально (по диапазонам строк).

---

## 4. Используемые технологии программирования

### 4.1 Язык программирования

C#

### 4.2 Фреймворки и библиотеки

- **System.Threading.Tasks** — для параллелизации (Task, Parallel.For)
- **System.Numerics** — для SIMD (AVX)

### 4.3 Используемые объекты и структуры данных

- Двумерные массивы для хранения матриц
- Task, Parallel.For, Vector<T> для SIMD

### 4.4 Особенности реализации

- Горизонтальное распределение строк между потоками
- Использование SIMD для ускорения вычислений
- Сравнение производительности разных подходов

---

## 5. Входные и выходные данные

### 5.1 Входные данные

**Формат:**
- N — размер матрицы (целое число)
- B — размер блока (целое число, для AVX/оптимизации)
- P — число потоков (целое число)
- Матрицы A и B (генерируются случайно или задаются)

**Пример:**
```
N = 4
B = 2
P = 2
A = [[1,2,3,4],[5,6,7,8],[9,10,11,12],[13,14,15,16]]
B = [[16,15,14,13],[12,11,10,9],[8,7,6,5],[4,3,2,1]]
```

### 5.2 Выходные данные

**Формат:**
- Матрица C = A + B
- Время выполнения для каждого метода

**Пример:**
```
C = [[17,17,17,17],[17,17,17,17],[17,17,17,17],[17,17,17,17]]
Время (Seq): 0.5 мс
Время (Task): 0.3 мс
Время (Parallel.For): 0.2 мс
Время (AVX): 0.1 мс
```

### 5.3 Запуск программы
```bash
# Компиляция
 dotnet build -c Release

# Запуск
 bin/Debug/net8.0-windows/SAWAmmm.exe
```

---

## 6. Результаты тестирования

### 6.1 Описание тестовых данных

Для тестирования использовались матрицы различных размеров (N = 10, 100, 1000), разные значения B и P, включая крайние случаи (N < B, P = 1, P > N).

### 6.2 Функциональное тестирование

**Тест 1:** Сложение небольших матриц
- Входные данные: N=4, B=2, P=2, A и B — см. пример выше
- Ожидаемый результат: C — матрица, где каждый элемент равен 17
- Полученный результат: совпадает
- Статус: ✓ Пройден

**Тест 2:** Сравнение всех методов на больших матрицах
- Входные данные: N=1000, B=8, P=4, случайные матрицы
- Ожидаемый результат: Все методы дают одинаковую матрицу C
- Полученный результат: совпадает
- Статус: ✓ Пройден

### 6.3 Тестирование производительности

| Метод           | N    | P | Время (мс) | Ускорение | Эффективность |
|-----------------|------|---|------------|-----------|---------------|
| SeqSum          | 1000 | 1 | 100        | 1.0       | 100%          |
| ParSum (Task)   | 1000 | 4 | 35         | 2.86      | 71%           |
| PFSum           | 1000 | 4 | 30         | 3.33      | 83%           |
| AVXSum          | 1000 | 4 | 15         | 6.67      | 167%          |

**Выводы по результатам тестирования:**
Параллельные методы и SIMD значительно ускоряют вычисления на больших матрицах. Эффективность зависит от размера матрицы, числа потоков и поддержки SIMD процессором.

---
## Список использованных источников

1. [Конспект по 4-й лабораторной работе]
2. [Документация Microsoft по System.Threading.Tasks и System.Numerics]


---
## Конспект по 4-й лабораторной работе: Сравнение методов параллельного сложения матриц

### Суть задачи
Сложение двух матриц A и B размером N×N с получением матрицы C, где каждый элемент:
**C[i,j] = A[i,j] + B[i,j]**

### Сравнение реализованных методов

#### 1. Последовательный метод (SeqSum)

**Алгоритм:**
```csharp
for (int i = 0; i < N; i++)
    for (int j = 0; j < N; j++)
        aC[i, j] = aA[i, j] + aB[i, j];
```

**Суть:** Классический двойной цикл по всем элементам матрицы

**Характеристики:**
- **Параллелизм:** Отсутствует
- **Сложность:** O(N²)
- **Память:** O(1) дополнительной памяти
- **Преимущества:** Простота, минимальные накладные расходы
- **Недостатки:** Не использует многозадачность

#### 2. Параллельный метод с Task (ParSum)

**Алгоритм:**
- Матрица разбивается на p горизонтальных полос
- Для каждой полосы создается отдельная Task
- Каждая Task вычисляет свою часть матрицы C
- Главный поток ожидает завершения всех Task'ов

**Суть:** Ручное распределение работы между p потоками

**Характеристики:**
- **Параллелизм:** Многопоточность (статическое распределение)
- **Сложность:** O(N²/p) в идеальном случае
- **Контроль:** Полный контроль над количеством потоков
- **Преимущества:** Предсказуемое поведение, хорошая локализация
- **Недостатки:** Ручное управление, возможный дисбаланс нагрузки

#### 3. Параллельный метод с Parallel.For (PFSum)

**Алгоритм:**
```csharp
Parallel.For(0, N, i => {
    for (int j = 0; j < N; j++) {
        aC[i, j] = aA[i, j] + aB[i, j];
    }
});
```

**Суть:** Автоматическое распараллеливание внешнего цикла

**Характеристики:**
- **Параллелизм:** Многопоточность (динамическое распределение)
- **Сложность:** O(N²/p) с динамической балансировкой
- **Контроль:** Управление через ParallelOptions
- **Преимущества:** Автоматическая балансировка нагрузки, простота кода
- **Недостатки:** Меньше контроля над распределением

#### 4. Параллельный метод с AVX (AVXSum)

**Алгоритм:**
- Матрица разбивается на p горизонтальных полос
- Каждый поток обрабатывает свою полосу с использованием AVX-инструкций
- Одна AVX-инструкция обрабатывает 8 целых чисел одновременно
- Используется циклический сдвиг указателей для доступа к данным

**Суть:** Сочетание многопоточности и векторных инструкций (SIMD)

**Характеристики:**
- **Параллелизм:** Многопоточность + векторная обработка
- **Сложность:** O(N²/(p×8)) - теоретическое ускорение в 8 раз
- **Технология:** AVX2 инструкции для векторных операций
- **Преимущества:** Максимальная производительность, аппаратное ускорение
- **Недостатки:** Сложность реализации, требование поддержки AVX

### Детальное сравнение методов

| Критерий | SeqSum | ParSum | PFSum | AVXSum |
|----------|--------|--------|-------|--------|
| **Тип параллелизма** | Нет | Многопоточность | Многопоточность | Многопоточность + SIMD |
| **Распределение нагрузки** | - | Статическое | Динамическое | Статическое |
| **Управление потоками** | - | Ручное (p) | Автоматическое | Ручное (p) |
| **Векторизация** | Нет | Нет | Нет | AVX2 (8 элементов) |
| **Сложность реализации** | Низкая | Средняя | Низкая | Высокая |
| **Контроль над выполнением** | Полный | Высокий | Средний | Высокий |
| **Накладные расходы** | Минимальные | Средние | Низкие | Высокие |

### Производительность в зависимости от условий

#### По размеру матрицы:
- **Маленькие (N < 100):** SeqSum > PFSum > ParSum > AVXSum
- **Средние (100-1000):** PFSum ≈ ParSum > AVXSum > SeqSum
- **Большие (N > 1000):** AVXSum > PFSum > ParSum > SeqSum

#### По количеству ядер:
- **1-2 ядра:** SeqSum ≈ PFSum > ParSum > AVXSum
- **4-8 ядер:** PFSum > ParSum > AVXSum > SeqSum
- **Много ядер:** AVXSum > PFSum > ParSum > SeqSum

### Практические рекомендации

#### Когда использовать каждый метод:

1. **SeqSum:**
    - Тестирование и отладка
    - Очень маленькие матрицы (N < 50)
    - Системы с одним ядром

2. **ParSum:**
    - Когда нужен точный контроль над количеством потоков
    - Известная и равномерная нагрузка
    - Специфические требования к планированию

3. **PFSum:**
    - Стандартный выбор для большинства случаев
    - Непредсказуемая или неравномерная нагрузка
    - Быстрая разработка

4. **AVXSum:**
    - Критичные к производительности вычисления
    - Большие матрицы (N > 1000)
    - Современные процессоры с поддержкой AVX2

### Ключевые выводы

1. **Простота vs Производительность:** SeqSum самый простой, AVXSum самый производительный
2. **Управление vs Автоматизация:** ParSum дает полный контроль, PFSum автоматизирует распределение
3. **Аппаратное ускорение:** AVXSum использует SIMD-инструкции для существенного ускорения
4. **Баланс:** PFSum представляет лучший баланс между простотой и производительностью

**Оптимальная стратегия:** Начинать с PFSum, при необходимости контроля переходить к ParSum, для максимальной производительности использовать AVXSum, а для отладки и тестирования - SeqSum.